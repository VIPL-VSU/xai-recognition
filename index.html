<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="A Survey on Interpretability in Visual Recognition">
  <meta name="citation_author" content="Wan, Qiyang">
  <meta name="citation_author" content="Gao, Chengzhi">
  <meta name="citation_author" content="Wang, Ruiping">
  <meta name="citation_author" content="Chen, Xilin">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="arXiv preprint arXiv:2507.11099">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2507.11099">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>A Survey on Interpretability in Visual Recognition</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

  <style>
    .block p {
      line-height: 1.5;
    }
  </style>
</head>

<body>
  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">A Survey on<br>Interpretability in Visual Recognition</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=B32XdrQAAAAJ&hl=en" target="_blank">Qiyang Wan</a>,
                </span>
                <span class="author-block">
                  <a href="#" target="_blank">Chengzhi Gao</a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=duIUwpwAAAAJ&hl=en" target="_blank">Ruiping
                    Wang</a>,
                </span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=vVx2v20AAAAJ&hl=en" target="_blank">Xilin Chen</a>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Key Laboratory of AI Safety of CAS, Institute of Computing
                  Technology,<br>Chinese Academy of Sciences(CAS), Beijing, China</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2507.11099.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/VIPL-VSU/xai-recognition" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>GitHub</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2507.11099" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img class="block" src="static/images/teaser.png" alt="Teaser Image"
            style="width:100%; height:auto; display:block; margin-left:auto; margin-right:auto;">
          <p class="subtitle has-text-centered">
            We propose a multi-dimensional taxonomy to systematize current XAI research in visual recognition. Beyond
            the framework, we explore evaluation metrics, MLLMs, and practical applications to provide a comprehensive
            roadmap.
          </p>
        </div>
      </div>
    </section>

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Visual recognition models have achieved unprecedented success in various tasks. While researchers aim to
                understand the underlying mechanisms of these models, the growing demand for deployment in
                safety-critical areas like autonomous driving and medical diagnostics has accelerated the development of
                eXplainable AI (XAI). Distinct from generic XAI, visual recognition XAI is positioned at the
                intersection of vision and language, which represent the two most fundamental human modalities and form
                the cornerstones of multimodal intelligence. This paper provides a systematic survey of XAI in visual
                recognition by establishing a multi-dimensional taxonomy from a human-centered perspective based on
                <b>intent</b>, <b>object</b>, <b>presentation</b>, and <b>methodology</b>. Beyond categorization, we
                summarize critical evaluation desiderata and metrics, conducting an extensive qualitative assessment
                across different categories and demonstrating quantitative benchmarks within specific dimensions.
                Furthermore, we explore the interpretability of Multimodal Large Language Models and practical
                applications, identifying emerging trends and opportunities. By synthesizing these diverse perspectives,
                this survey provides an insightful roadmap to inspire future research on the interpretability of visual
                recognition models.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <section class="section" id="taxonomy">
      <div class="container is-max-desktop content">
        <div class="block">
          <h2 class="title">Taxonomy</h2>
        </div>
        <div class="block">
          <p class="subtitle">
            This section shows the proposed taxonomy and corresponding method groups of XAI in visual recognition, with
            a three-level hierarchy: <b>dimensions</b>, <b>groups</b>, and <b>subgroups</b>.
          </p>
        </div>
        <img class="block" src="static/images/taxonomy.png" alt="Taxonomy Image"
          style="width:100%; height:auto; display:block; margin-left:auto; margin-right:auto;">
        <div class="block">
          <p class="subtitle">
            Four dimensions are defined to categorize existing methods: <b>intent</b>, <b>object</b>,
            <b>presentation</b>, and <b>methodology</b>.
          </p>
          <ul class="is-size-5">
            <li><strong>Intent:</strong> <em>What is the purpose of bringing in interpretability?</em></li>
            <li><strong>Object:</strong> <em>What does the generated explanation focus on?</em></li>
            <li><strong>Presentation:</strong> <em>What does the generated explanation look like?</em></li>
            <li><strong>Methodology:</strong> <em>How is the explanation generated?</em></li>
          </ul>
        </div>
      </div>
    </section>

    <section class="section" id="paperlist">
      <div class="container is-max-desktop content">
        <div class="block">
          <h2 class="title">Tags for Paper List</h2>
        </div>
        <div class="block">
          <p class="subtitle">
            The table below introduces various badges used to tag papers in terms of the four key dimensions. The badges
            help to efficiently identify research papers based on their interpretability approaches.
          </p>
        </div>
        <div class="block table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth">
            <thead>
              <tr>
                <th style="width: 150px;">Badge</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><img src="https://img.shields.io/badge/I-passive-e97132" alt="I-passive"></td>
                <td><strong>Intent</strong> is <em>passive</em>. Methods that explain already trained models by
                  revealing
                  their recognition process.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/I-active-e97132" alt="I-active"></td>
                <td><strong>Intent</strong> is <em>active</em>. Methods that integrate interpretability during model
                  construction, making the process inherently interpretable.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/O-local-4ea72e" alt="O-local"></td>
                <td><strong>Object</strong> is <em>local</em>. Explanation focused on individual samples, such as
                  diagnostic suggestions for each patient.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/O-semilocal-4ea72e" alt="O-semilocal"></td>
                <td><strong>Object</strong> is <em>semilocal</em>. Explanation that highlights common characteristics
                  within a class of samples.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/O-global-4ea72e" alt="O-global"></td>
                <td><strong>Object</strong> is <em>global</em>. Explanation of the entire model's decision rules, often
                  category-independent.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/P-scalar-0f9ed5" alt="P-scalar"></td>
                <td><strong>Presentation</strong> is <em>scalar</em>. Explanation presented in quantitative forms, such
                  as
                  numerical scores.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/P-attention-0f9ed5" alt="P-attention"></td>
                <td><strong>Presentation</strong> is <em>attention</em>. Used to highlight important features or regions
                  contributing to a decision.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/P-structure-0f9ed5" alt="P-structure"></td>
                <td><strong>Presentation</strong> is <em>structured</em>. Explanation involving structured
                  representations
                  such as graphs.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/P-semantic-0f9ed5" alt="P-semantic"></td>
                <td><strong>Presentation</strong> is <em>semantic unit</em>. Explanation decomposed into
                  human-understandable semantic concepts.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/P-exemplar-0f9ed5" alt="P-exemplar"></td>
                <td><strong>Presentation</strong> is <em>exemplar</em>. Explanation through examples that illustrate
                  specific model behaviors.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/M-association-a02b93" alt="M-association"></td>
                <td><strong>Methodology</strong> is <em>association</em>. Methods that model correlations to show the
                  relationships and patterns between inputs and outputs.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/M-intervention-a02b93" alt="M-intervention"></td>
                <td><strong>Methodology</strong> is <em>intervention</em>. Methods predicting outcomes after making
                  active
                  changes to the model or its inputs.</td>
              </tr>
              <tr>
                <td><img src="https://img.shields.io/badge/M-counterfactual-a02b93" alt="M-counterfactual"></td>
                <td><strong>Methodology</strong> is <em>conterfactual</em>. Simulates alternative scenarios by
                  perturbing
                  inputs to explore the potential outcomes that could arise under different conditions.</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="block">
          <p class="subtitle">
            The full paper list with tags can be found in
            <a href="https://github.com/VIPL-VSU/xai-recognition?tab=readme-ov-file#paper-list" target="_blank">
              our GitHub repository
            </a>.
          </p>
        </div>
      </div>
    </section>

    <section class="section" id="metric">
      <div class="container is-max-desktop content">
        <div class="block">
          <h2 class="title">Metrics</h2>
        </div>
        <div class="block">
          <p class="subtitle">
            In this section we provide the full tables of metrics (i.e. Table 4 in the paper).
          </p>
        </div>
        <div class="block table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth">
            <thead>
              <tr class="has-background-light">
                <th class="has-text-centered">Type</th>
                <th class="has-text-centered">Metric</th>
                <th class="has-text-centered">Undst.</th>
                <th class="has-text-centered">Fidel.</th>
                <th class="has-text-centered">Conti.</th>
                <th class="has-text-centered">Effic.</th>
                <th class="has-text-centered">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="17"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Localization Metrics
                </td>
                <td class="pl-4">AOPC <sup>[<a href="#ref-132">132</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure explanation quality by the confidence drop when perturbing salient regions</td>
              </tr>
              <tr>
                <td class="pl-4">Pointing Game (PG) <sup>[<a href="#ref-133">133</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Measure localization accuracy by calculating the hit rate of the attention map's peak point falling
                  within ground-truth regions</td>
              </tr>
              <tr>
                <td class="pl-4">Deletion, Insertion <sup>[<a href="#ref-134">134</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Track class probability changes as the most important pixels are removed and added</td>
              </tr>
              <tr>
                <td class="pl-4">MCS, IDR <sup>[<a href="#ref-135">135</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td rowspan="2">Introduce BAM metrics to evaluate attribution methods across models and inputs</td>
              </tr>
              <tr>
                <td class="pl-4">IIR <sup>[<a href="#ref-135">135</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">Bias of Attribution Map, Unexplainable Feature <sup>[<a href="#ref-133">133</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td rowspan="2">Develop four metrics for attribution maps to enable ground-truth-free evaluation</td>
              </tr>
              <tr>
                <td class="pl-4">Robustness, Mutual Verification <sup>[<a href="#ref-133">133</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">Faithfulness (F) <sup>[<a href="#ref-136">136</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure Pearson correlation between pixel relevance and changes after perturbation</td>
              </tr>
              <tr>
                <td class="pl-4">HI score <sup>[<a href="#ref-137">137</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Assess heatmaps by rewarding meaningful activations and penalizing irrelevant ones</td>
              </tr>
              <tr>
                <td class="pl-4">POMPOM <sup>[<a href="#ref-138">138</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Calculate the percentage of meaningful pixels leakage outside target regions</td>
              </tr>
              <tr>
                <td class="pl-4">FP Error, FN Error <sup>[<a href="#ref-139">139</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Quantify pixel-wise errors between saliency maps and ground truth masks</td>
              </tr>
              <tr>
                <td class="pl-4">iAUC, IntIoSR <sup>[<a href="#ref-140">140</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td rowspan="2">Modify PG to use intersection ratio between salient area and ground truth mask</td>
              </tr>
              <tr>
                <td class="pl-4">CS, SENSmax <sup>[<a href="#ref-140">140</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">GTC, SC, IoU <sup>[<a href="#ref-141">141</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Quantify overlap between model’s saliency map and human-defined ground truth</td>
              </tr>
              <tr>
                <td class="pl-4">MeGe, ReCo <sup>[<a href="#ref-125">125</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Assess generalizability and consistency of explanations for quality and trustworthiness</td>
              </tr>
              <tr>
                <td class="pl-4">RMA, RRA <sup>[<a href="#ref-142">142</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Propose mass accuracy and rank accuracy for heatmap evaluation by CLEVR-XAI dataset</td>
              </tr>
              <tr>
                <td class="pl-4">AR, AP <sup>[<a href="#ref-68">68</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure how much of the relevant parts of test images are considered relevant by a model</td>
              </tr>

              <tr>
                <td class="has-background-success-light has-text-weight-bold is-vcentered" rowspan="14"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Semantic Metrics
                </td>
                <td class="pl-4">Completeness Score <sup>[<a href="#ref-76">76</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure how well concept scores can reconstruct the model's original predictions</td>
              </tr>
              <tr>
                <td class="pl-4">N<sup>fg</sup><sub>concept</sub>, N<sup>bg</sup><sub>concept</sub>, λ ratio <sup>[<a href="#ref-77">77</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td rowspan="3">Quantify “dark-matter” visual concepts encoded during the knowledge distillation</td>
              </tr>
              <tr>
                <td class="pl-4">ρ value <sup>[<a href="#ref-77">77</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">D<sub>mean</sub>, D<sub>std</sub> <sup>[<a href="#ref-77">77</a>]</sup></td>
                <td></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
              </tr>
              <tr>
                <td class="pl-4">Fid<sub>c</sub>, Fid<sub>r</sub> <sup>[<a href="#ref-78">78</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure fidelity of concept-based explanations for classification and regression models</td>
              </tr>
              <tr>
                <td class="pl-4">Faithfulness, Fidelity, Intervention on Concepts (IoC) <sup>[<a href="#ref-80">80</a>]</sup></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td rowspan="2">Metrics to assess faithfulness, fidelity, explanation error, and concept intervention
                </td>
              </tr>
              <tr>
                <td class="pl-4">Explanation Error <sup>[<a href="#ref-80">80</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">AIPD, AIFD <sup>[<a href="#ref-66">66</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Compute average inter-class distance for prototypes and nearest local representations</td>
              </tr>
              <tr>
                <td class="pl-4">Factuality, Groundability <sup>[<a href="#ref-143">143</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Measure concept accuracy and vision-language alignment with human interpretations</td>
              </tr>
              <tr>
                <td class="pl-4">CDR <sup>[<a href="#ref-55">55</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td></td>
                <td rowspan="2">Summarize participants' responses in the user study of discovered concepts</td>
              </tr>
              <tr>
                <td class="pl-4">CC, MIC <sup>[<a href="#ref-55">55</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
              </tr>
              <tr>
                <td class="pl-4">TCPC, TOPC <sup>[<a href="#ref-144">144</a>]</sup></td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td>Measure concept weight stability and output prediction stability under perturbation</td>
              </tr>
              <tr>
                <td class="pl-4">CUE <sup>[<a href="#ref-145">145</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td class="has-text-centered">✔</td>
                <td>Use both average length and quantity of concepts to evaluate concepts’ efficiency</td>
              </tr>
              <tr>
                <td class="pl-4">RC, IC <sup>[<a href="#ref-82">82</a>]</sup></td>
                <td class="has-text-centered">✔</td>
                <td class="has-text-centered">✔</td>
                <td></td>
                <td></td>
                <td>Evaluate concept importance and correctness during the concept extraction process</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="block px-4 is-size-7">
          <p id="ref-55">[55] B. Wang, L. Li, Y. Nakashima, and H. Nagahara, “Learning Bottleneck Concepts in Image Classification,” in CVPR, 2023, pp. 10962-10971.</p>
          <p id="ref-66">[66] C. Wang et al., “Learning Support and Trivial Prototypes for Interpretable Image Classification,” in ICCV, 2023, pp. 2062-2072.</p>
          <p id="ref-68">[68] M. T. Hagos, N. Belton, K. M. Curran, and B. Mac Namee, “Distance-Aware Explanation Based Learning,” in 2023 IEEE 35th International Conference on Tools with Artificial Intelligence (ICTAI), 2023, pp. 279-286.</p>
          <p id="ref-76">[76] C.-K. Yeh, B. Kim, S. Arik, C.-L. Li, T. Pfister, and P. Ravikumar, “On Completeness-Aware Concept-Based Explanations in Deep Neural Networks,” NeurIPS, vol. 33, pp. 20554-20565, 2020.</p>
          <p id="ref-77">[77] X. Cheng, Z. Rao, Y. Chen, and Q. Zhang, “Explaining Knowledge Distillation by Quantifying the Knowledge,” in CVPR, 2020, pp. 12925-12935.</p>
          <p id="ref-78">[78] R. Zhang, P. Madumal, T. Miller, K. A. Ehinger, and B. I. Rubinstein, “Invertible Concept-Based Explanations for CNN Models with Non-negative Concept Activation Vectors,” in AAAI, vol. 35, 2021, pp. 11682-11690.</p>
          <p id="ref-80">[80] A. Sarkar, D. Vijaykeerthy, A. Sarkar, and V. N. Balasubramanian, “A Framework for Learning Ante-hoc Explainable Models Via Concepts,” in CVPR, 2022, pp. 10286-10295.</p>
          <p id="ref-82">[82] A. F. Posada-Moreno, N. Surya, and S. Trimpe, “ECLAD: Extracting Concepts with Local Aggregated Descriptors,” Pattern Recognition, vol. 147, p. 110146, 2024.</p>
          <p id="ref-125">[125] T. Fel, D. Vigouroux, R. Cad`ene, and T. Serre, “How Good Is Your Explanation? Algorithmic Stability Measures to Assess the Quality of Explanations for Deep Neural Networks,” in WACV, 2022, pp. 720-730.</p>
          <p id="ref-132">[132] W. Samek, A. Binder, G. Montavon, S. Lapuschkin, and K.-R. M¨ uller, “Evaluating the Visualization of What a Deep Neural Network Has Learned,” IEEE Transactions on Neural Networks and Learning Systems, vol. 28, no. 11, pp. 2660-2673, 2016.</p>
          <p id="ref-133">[133] J. Zhang, S. A. Bargal, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff, “Top-Down Neural Attention by Excitation Backprop,” International Journal of Computer Vision, vol. 126, no. 10, pp. 1084-1102, 2018.</p>
          <p id="ref-134">[134] V. Petsiuk, A. Das, and K. Saenko, “RISE: Randomized Input Sampling for Explanation of Black-Box Models,” arXiv:1806.07421, 2018.</p>
          <p id="ref-135">[135] M. Yang and B. Kim, “Benchmarking Attribution Methods with Relative Feature Importance,” arXiv:1907.09701, 2019.</p>
          <p id="ref-136">[136] R. Tomsett, D. Harborne, S. Chakraborty, P. Gurram, and A. Preece, “Sanity Checks for Saliency Metrics,” in AAAI, vol. 34, 2020, pp. 6021-6029.</p>
          <p id="ref-137">[137] A. Theodorus, M. Nauta, and C. Seifert, “Evaluating CNN Interpretability on Sketch Classification,” in Twelfth International Conference on Machine Vision (ICMV 2019), vol. 11433, 2020, pp. 475-482.</p>
          <p id="ref-138">[138] I. Rio-Torto, K. Fernandes, and L. F. Teixeira, “Understanding the Decisions of CNNs: An In-Model Approach,” Pattern Recognition Letters, vol. 133, pp. 373-380, 2020.</p>
          <p id="ref-139">[139] S. Mohseni, J. E. Block, and E. Ragan, “Quantitative Evaluation of Machine Learning Explanations: A Human-Grounded Benchmark,” in Proceedings of the 26th International Conference on Intelligent User Interfaces, 2021, pp. 22-31.</p>
          <p id="ref-140">[140] X.-H. Li, Y. Shi, H. Li,W. Bai, C. C. Cao, and L. Chen, “An Experimental Study of Quantitative Evaluations on Saliency Methods,” in Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, 2021, pp. 3200-3208.</p>
          <p id="ref-141">[141] A. Boggust, B. Hoover, A. Satyanarayan, and H. Strobelt, “Shared Interest: Measuring Human-AI Alignment to Identify Recurring Patterns in Model Behavior,” in Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, 2022, pp. 1-17.</p>
          <p id="ref-142">[142] L. Arras, A. Osman, and W. Samek, “CLEVR-XAI: A Benchmark Dataset for the Ground Truth Evaluation of Neural Network Explanations,” Information Fusion, vol. 81, pp. 14-40, 2022.</p>
          <p id="ref-143">[143] Y. Yang, A. Panagopoulou, S. Zhou, D. Jin, C. Callison-Burch, and M. Yatskar, “Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification,” in CVPR, 2023, pp. 19187-19197.</p>
          <p id="ref-144">[144] S. Lai, L. Hu, J. Wang, L. Berti-Equille, and D. Wang, “Faithful Vision-Language Interpretation Via Concept Bottleneck Models,” in ICLR, 2023.</p>
          <p id="ref-145">[145] C. Shang, S. Zhou, H. Zhang, X. Ni, Y. Yang, and Y. Wang, “Incremental Residual Concept Bottleneck Models,” in CVPR, 2024, pp. 11030-11040.</p>
        </div>
      </div>
    </section>

    <section class="section" id="rw">
      <div class="container is-max-desktop content">
        <div class="block">
          <h2 class="title">Related Survey</h2>
        </div>
        <div class="block">
          <p class="subtitle">
            This section summarizes the related surveys of our work, organized into three groups.
          </p>
        </div>
        <div class="block">
          <h4 class="title">Generic AI Models</h4>
        </div>
        <div class="block">
          <p class="subtitle is-size-6">
            XAI techniques, classification methods, evaluation metrics, and future challenges for various AI models.
          </p>
        </div>
        <div class="block table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth">
            <thead>
              <tr class="has-background-light">
                <th class="has-text-centered">Type</th>
                <th class="has-text-centered">Reference</th>
                <th class="has-text-centered">Year</th>
                <th class="has-text-centered">Literature Coverage</th>
                <th class="has-text-centered">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="26"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  XAI Surveys on Generic AI Models
                </td>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S095741742401577X"
                    target="_blank">abusitta2024survey</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2018-2024</td>
                <td class=" is-vcentered">Propose a classification of XAI techniques, emphasizing applications in
                  cybersecurity and future challenges</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/S10618-022-00867-8"
                    target="_blank">schwalbe2024comprehensive</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Propose a unified taxonomy of XAI methods and provide use-case-oriented
                  insights
                </td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s12559-023-10179-8"
                    target="_blank">hassija2024interpreting</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2016-2024</td>
                <td class=" is-vcentered">Review XAI models, evaluation metrics, challenges, and trends to enhance
                  transparency</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0925231224008828"
                    target="_blank">mersha2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2015-2024</td>
                <td class=" is-vcentered">Deliver a review of XAI, examining methods, applications, and principles to
                  enhance transparency</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-031-65392-6_23"
                    target="_blank">mazhar2024survey</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2018-2023</td>
                <td class=" is-vcentered">Survey XAI methods for deep learning, investigating techniques, tools, and
                  future research directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://dl.acm.org/doi/abs/10.1145/3675392"
                    target="_blank">chander2024toward</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2023</td>
                <td class=" is-vcentered">Discuss trustworthy AI, focusing on robustness and explainability to enhance
                  safety and reliability</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10188681/"
                    target="_blank">chamola2023review</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2019-2023</td>
                <td class=" is-vcentered">Evaluate trustworthy and explainable AI, focusing on transparency and
                  reliability across industries</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s44230-023-00038-y"
                    target="_blank">yang2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2017-2023</td>
                <td class=" is-vcentered">Review XAI research, focusing on key areas, taxonomies, applications, and
                  future
                  directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S277266222300070X"
                    target="_blank">saranya2023systematic</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2020-2022</td>
                <td class=" is-vcentered">Conduct a systematic review of XAI applications across various fields and
                  suggest directions for future research</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0950705123000230"
                    target="_blank">saeed2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2017-2022</td>
                <td class=" is-vcentered">Conduct a systematic meta-survey of XAI challenges and future research across
                  development phases</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a
                    href="https://www.sciencedirect.com/science/article/pii/B9780323960984000089"
                    target="_blank">samek2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2017-2022</td>
                <td class=" is-vcentered">Introduce XAI techniques for deep neural networks, emphasizing challenges and
                  future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://dl.acm.org/doi/abs/10.1145/3561048"
                    target="_blank">dwivedi2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2017-2021</td>
                <td class=" is-vcentered">Survey XAI techniques, classify approaches, and guide framework selection for
                  interpretable AI systems</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-031-04083-2_2"
                    target="_blank">holzinger2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2019-2022</td>
                <td class=" is-vcentered">Present a concise overview of 17 key XAI methods for beginners</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0925231222012218"
                    target="_blank">saleem2022explaining</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2019-2022</td>
                <td class=" is-vcentered">Review global interpretation methods in XAI, highlighting strengths,
                  weaknesses,
                  and future opportunities</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S002002552201132X"
                    target="_blank">ding2022explainability</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2016-2022</td>
                <td class=" is-vcentered">Discuss XAI principles, taxonomy, evaluation, and challenges, suggesting
                  future
                  research directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.jair.org/index.php/jair/article/view/13200"
                    target="_blank">ras2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2014-2022</td>
                <td class=" is-vcentered">Guide readers through explainable deep learning, discussing key methods,
                  evaluations, and future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a
                    href="https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.short"
                    target="_blank">rudin2022interpretable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2013-2022</td>
                <td class=" is-vcentered">Identify 10 technical challenge areas and provide historical and background
                  context</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9626294/"
                    target="_blank">hanif2021survey</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2017-2021</td>
                <td class=" is-vcentered">Survey XAI techniques, emphasizing the need for transparent and responsible AI
                  to build trust</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9521221/"
                    target="_blank">zhang2021survey</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2015-2021</td>
                <td class=" is-vcentered">Propose a taxonomy of neural network interpretability based on engagement,
                  explanation type, and focus</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9369420/"
                    target="_blank">samek2021explaining</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2014-2021</td>
                <td class=" is-vcentered">Offer an overview of post-hoc explanations, evaluate interpretability methods,
                  and demonstrate XAI applications</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2101.09429"
                    target="_blank">islam2021explainable</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2018-2020</td>
                <td class=" is-vcentered">Analyze XAI methods for credit default prediction, compare advantages, and
                  suggest future research</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9380482/"
                    target="_blank">fan2021interpretability</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2014-2020</td>
                <td class=" is-vcentered">Propose a taxonomy and discuss applications and future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2006.11371"
                    target="_blank">das2020opportunities</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2017-2020</td>
                <td class=" is-vcentered">Deliver an overview of XAI techniques, including taxonomy, methods,
                  principles,
                  and evaluation</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S1574013719302527"
                    target="_blank">huang2020survey</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2015-2020</td>
                <td class=" is-vcentered">Review research on making DNNs safe, concentrating on verification, testing,
                  attacks, and interpretability</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S1566253519308103"
                    target="_blank">arrieta2020explainable</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2007-2020</td>
                <td class=" is-vcentered">Explore the importance of explainability in AI and present a taxonomy of XAI
                  techniques</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-030-49760-6_4"
                    target="_blank">ferreira2020people</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2018-2019</td>
                <td class=" is-vcentered">Explore AI explainability from CS and HCI perspectives, concentrating on
                  goals,
                  recipients, and context</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="block mt-6">
          <h4 class="title">Vision-Related Fields</h4>
        </div>
        <div class="block">
          <p class="subtitle is-size-6">
            XAI research in visual tasks, visualization techniques, architectures, multimodal models, and reinforcement
            learning.
          </p>
        </div>
        <div class="block table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth">
            <thead>
              <tr class="has-background-light">
                <th class="has-text-centered">Type</th>
                <th class="has-text-centered">Reference</th>
                <th class="has-text-centered">Year</th>
                <th class="has-text-centered">Literature Coverage</th>
                <th class="has-text-centered">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="3"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Visual Task
                </td>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S2405959524001115"
                    target="_blank">gipivskis2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey XAI in semantic segmentation, categorizing evaluation metrics and
                  future
                  challenges</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2312.12936"
                    target="_blank">poeta2023concept</a>
                </td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2018-2023</td>
                <td class=" is-vcentered">Review concept-based XAI methods, offering taxonomy, guidelines, and
                  evaluations
                  for the future</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0031320321002892"
                    target="_blank">bai2021explainable</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2015-2021</td>
                <td class=" is-vcentered">Introduce papers on explainable deep learning, efficiency, and robustness in
                  pattern recognition</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="3"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Visualization
                </td>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S1566253524000812"
                    target="_blank">baniecki2024adversarial</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey adversarial attacks on XAI, outlining security challenges and
                  suggesting
                  future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0097849321001886"
                    target="_blank">alicioglu2022survey</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2021</td>
                <td class=" is-vcentered">Review trends and challenges in visual analytics for XAI, focusing on deep
                  learning model interpretation</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-319-54024-5_6"
                    target="_blank">seifert2017visualizations</a></td>
                <td class="has-text-centered is-vcentered">2017</td>
                <td class="has-text-centered is-vcentered">2014-2016</td>
                <td class=" is-vcentered">Survey visualization methods for DNNs, focusing on insights gained in computer
                  vision</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="3"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Architecture
                </td>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/2073-431X/13/4/92"
                    target="_blank">fantozzi2024explainability</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey transformer explainability, categorizing by components, applications,
                  and
                  visualization</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2311.06786"
                    target="_blank">kashefi2023explainability</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2021-2023</td>
                <td class=" is-vcentered">Review explainability methods for vision transformers, categorizing approaches
                  and evaluation criteria</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/2079-9292/13/1/175"
                    target="_blank">stassin2023explainability</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2019-2023</td>
                <td class=" is-vcentered">Evaluate XAI for vision transformers, highlighting challenges in metrics,
                  convergence, and adaptation</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="4"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Multimodal
                </td>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2501.12203"
                    target="_blank">kazmierczak2025explainability</a></td>
                <td class="has-text-centered is-vcentered">2025</td>
                <td class="has-text-centered is-vcentered">2017-2025</td>
                <td class=" is-vcentered">Survey integration of foundation models with explainable AI in the vision
                  domain
                </td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2412.02104"
                    target="_blank">dang2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Analyze recent advances in Multimodal XAI, focusing on methods, datasets, and
                  evaluation metrics</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10689601/"
                    target="_blank">rodis2024multimodal</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2016-2024</td>
                <td class=" is-vcentered">Survey interpretability of MLLMs, categorizing evaluations and future
                  directions
                </td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2412.14056" target="_blank">sun2024review</a>
                </td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2015-2024</td>
                <td class=" is-vcentered">Review research on interpretability of MLLMs, focusing on challenges, metrics,
                  and future directions</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="4"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Reinforcement Learning
                </td>
                <td class=" is-vcentered"><a href="https://dl.acm.org/doi/abs/10.1145/3616864"
                    target="_blank">milani2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey XRL techniques, introduce a taxonomy, and outline challenges and future
                  directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s10994-024-06543-w"
                    target="_blank">glanois2024survey</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2015-2024</td>
                <td class=" is-vcentered">Survey interpretability approaches in reinforcement learning, focusing on
                  inputs, models, and decisions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s00521-023-08423-1"
                    target="_blank">dazeley2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2015-2023</td>
                <td class=" is-vcentered">Introduce the Causal XRL Framework, unify XRL research, and explore future
                  Broad-XAI development</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-030-57321-8_5"
                    target="_blank">puiutta2020explainable</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2017-2019</td>
                <td class=" is-vcentered">Survey XRL methods and highlight the need for interdisciplinary human-centered
                  explanations</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="4"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Others
                </td>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2409.00743"
                    target="_blank">hu2024interpretable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2021-2024</td>
                <td class=" is-vcentered">Review explainable clustering methods, emphasizing transparency and ethics in
                  high-stakes applications</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s10462-024-10916-x"
                    target="_blank">schneider2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2019-2024</td>
                <td class=" is-vcentered">Review XAI in generative AI, addressing challenges, categories, criteria, and
                  future research directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.jair.org/index.php/jair/article/view/12228"
                    target="_blank">burkart2021survey</a></td>
                <td class="has-text-centered is-vcentered">2021</td>
                <td class="has-text-centered is-vcentered">2015-2021</td>
                <td class=" is-vcentered">Survey explainable supervised learning methods, highlighting principles,
                  methodologies, and directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9050829/"
                    target="_blank">li2020survey</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2015-2020</td>
                <td class=" is-vcentered">Survey explanation methods, focusing on data-driven and knowledge-aware
                  approaches, and applications</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="block mt-6">
          <h4 class="title">Visual Applications</h4>
        </div>
        <div class="block">
          <p class="subtitle is-size-6">
            Applications of XAI in medical imaging, industrial manufacturing, smart cities, and cybersecurity.
          </p>
        </div>
        <div class="block table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth">
            <thead>
              <tr class="has-background-light">
                <th class="has-text-centered">Type</th>
                <th class="has-text-centered">Reference</th>
                <th class="has-text-centered">Year</th>
                <th class="has-text-centered">Literature Coverage</th>
                <th class="has-text-centered">Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="11"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Medical Imaging
                </td>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/2313-433X/10/10/239"
                    target="_blank">bhati2024survey</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey interpretability and visualization techniques for deep learning in
                  medical imaging</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://arxiv.org/abs/2410.02331" target="_blank">hou2024self</a>
                </td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Survey self-explainable AI for medical image analysis: methods, challenges,
                  and future research</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a
                    href="https://www.annualreviews.org/content/journals/10.1146/annurev-pathmechdis-051222-113147"
                    target="_blank">klauschen2024toward</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2015-2023</td>
                <td class=" is-vcentered">Explore diagnostic pathology: classification, biomarker quantification,
                  transparency, XAI solutions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0720048X23001006"
                    target="_blank">borys2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2020-2022</td>
                <td class=" is-vcentered">Review non-saliency XAI methods in medical imaging for clinicians</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/1424-8220/23/2/634"
                    target="_blank">chaddad2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2019-2022</td>
                <td class=" is-vcentered">Survey XAI techniques, categorize challenges, and suggest future directions in
                  medical imaging</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.sciencedirect.com/science/article/pii/S0010482523001336"
                    target="_blank">nazir2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2017-2022</td>
                <td class=" is-vcentered">Survey XAI for medical imaging diagnostics, analyze challenges, and propose
                  future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/1424-8220/22/20/8068"
                    target="_blank">sheu2022survey</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2022</td>
                <td class=" is-vcentered">Survey medical XAI: evaluations, case studies, human-machine collaboration,
                  and the future</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s00530-022-00960-4"
                    target="_blank">teng2022survey</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2019-2021</td>
                <td class=" is-vcentered">Review interpretability in medical diagnosis: methods, applications,
                  challenges, and future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wsbm.1548"
                    target="_blank">jin2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2016-2021</td>
                <td class=" is-vcentered">Review interpretability in healthcare: methods, advantages, applications, and
                  future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9233366/"
                    target="_blank">tjoa2020survey</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2015-2020</td>
                <td class=" is-vcentered">Categorize AI interpretability approaches to guide cautious application in
                  medical practices</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/chapter/10.1007/978-3-030-50402-1_4"
                    target="_blank">pocevivciute2020survey</a></td>
                <td class="has-text-centered is-vcentered">2020</td>
                <td class="has-text-centered is-vcentered">2015-2020</td>
                <td class=" is-vcentered">Survey XAI in digital pathology: techniques, uncertainty estimation, and
                  cross-disciplinary insights</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="4"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Industry/Manufacturing
                </td>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s10845-023-02304-z"
                    target="_blank">naqvi2024survey</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2001-2023</td>
                <td class=" is-vcentered">Survey ontology-based and semantic-based XAI for transparent AI decisions in
                  manufacturing</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10449717/"
                    target="_blank">alexander2024interrogative</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2020-2022</td>
                <td class=" is-vcentered">Survey explainable AI applications in manufacturing, highlight research, and
                  propose future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://dl.acm.org/doi/abs/10.1145/3609333"
                    target="_blank">li2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2016-2023</td>
                <td class=" is-vcentered">Survey explainable anomaly detection: techniques, taxonomy, ethics, and
                  guidance for practitioners</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9695219/"
                    target="_blank">ahmed2022artificial</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2021</td>
                <td class=" is-vcentered">Survey AI and XAI methods in Industry 4.0 for autonomous decision-making and
                  transparency</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="3"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Smart City
                </td>
                <td class=" is-vcentered"><a href="https://www.mdpi.com/2079-9292/12/4/1020"
                    target="_blank">javed2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2018-2023</td>
                <td class=" is-vcentered">Survey XAI developments in smart cities, focusing on use cases, challenges,
                  and research directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10158334/"
                    target="_blank">kok2023explainable</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2018-2023</td>
                <td class=" is-vcentered">Examine XAI in IoT: transparent models, challenges, foresee future directions,
                  and classify studies</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9930971/"
                    target="_blank">jagatheesaperumal2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2022</td>
                <td class=" is-vcentered">Study XAI in IoT: assess frameworks, security, IoMT, IIoT, IoCT, edge XAI, and
                  future directions</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="3"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Cybersecurity
                </td>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10143992/"
                    target="_blank">rjoub2023survey</a></td>
                <td class="has-text-centered is-vcentered">2023</td>
                <td class="has-text-centered is-vcentered">2020-2023</td>
                <td class=" is-vcentered">Survey XAI in cybersecurity: approaches, challenges, limitations, and future
                  research directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://link.springer.com/article/10.1007/s12243-022-00926-7"
                    target="_blank">charmet2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2022</td>
                <td class=" is-vcentered">Survey XAI in cybersecurity: applications, security concerns, challenges, and
                  future directions</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/9877919/"
                    target="_blank">capuano2022explainable</a></td>
                <td class="has-text-centered is-vcentered">2022</td>
                <td class="has-text-centered is-vcentered">2018-2022</td>
                <td class=" is-vcentered">Conduct in-depth study on XAI in cybersecurity: applications, challenges,
                  methods, and the future</td>
              </tr>
              <tr>
                <td class="has-background-info-light has-text-weight-bold is-vcentered" rowspan="2"
                  style="writing-mode: vertical-rl; transform: rotate(180deg); white-space: nowrap; text-align: center; vertical-align: middle; padding: 1em 0;">
                  Others
                </td>
                <td class=" is-vcentered">hohl2024opening</td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2017-2024</td>
                <td class=" is-vcentered">Perform systematic review of XAI methods, trends, and challenges in Remote
                  Sensing</td>
              </tr>
              <tr>
                <td class=" is-vcentered"><a href="https://ieeexplore.ieee.org/abstract/document/10459028/"
                    target="_blank">alizadehsani2024explainable</a></td>
                <td class="has-text-centered is-vcentered">2024</td>
                <td class="has-text-centered is-vcentered">2020-2023</td>
                <td class=" is-vcentered">Review XAI methods in drug discovery, identify challenges, applications, and
                  future directions</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@article{wan2025survey,
  title={A Survey on Interpretability in Visual Recognition},
  author={Wan, Qiyang and Gao, Chengzhi and Wang, Ruiping and Chen, Xilin},
  journal={arXiv preprint arXiv:2507.11099},
  year={2025},
  url={https://vipl-vsu.github.io/xai-recognition/}
}</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                © 2025 Institute of Computing Technology, Chinese Academy of Sciences | Academic Use
              </p>
              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                You are free to borrow the source code of this website, we just ask that you link back to this page in
                the footer. <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>